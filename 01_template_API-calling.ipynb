{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqlgeXvwytQuNER9aBCLSJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vanderbilt-data-science/poschat-dssg/blob/main/01_template_API-calling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making API Calls to OpenAI Models\n",
        "\n",
        "This notebook outlines the basic setup for making API calls to OpenAI's models from within a jupyter notebook.\n",
        "\n",
        "It is meant as a \"template\" notebook - it has simple functionalities laid out that can be built upon later to make more complex systems."
      ],
      "metadata": {
        "id": "fWzx5aJIy6oJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1. Setup\n",
        "\n",
        "Before we can start writing code to make the calls, we need to do some setup. This will include installing packages, importing packages, and giving ourself model access with our API key."
      ],
      "metadata": {
        "id": "tC2JVFal06No"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installing necessary packages\n",
        "Some packages need to be installed into our current environment before we're able to use them.\n",
        "This cell will print out some short messages as it works to collect those packages for us."
      ],
      "metadata": {
        "id": "BttYl2T6zbBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install -q openai\n",
        "!pip install -q PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hp5XzOIjzkSV",
        "outputId": "d4d81ee2-3102-4445-fb4f-5e08c1b12be8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing those packages\n",
        "In this code, we'll be reading in a PDF using the PyPDF2 package, and calling on OpenAI's models using the openai package.\n",
        "Here, we import those in so that we can use them.\n",
        "We will also import the getpass and os libraries, which will allow us to easily paste our OpenAI API key directly into this notebook."
      ],
      "metadata": {
        "id": "imVK3MqnzvLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import PyPDF2\n",
        "from getpass import getpass\n",
        "import os"
      ],
      "metadata": {
        "id": "blLI-Zkrznw-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding in our API key\n",
        "\n",
        "The final setup step we need is to add our API key, so that OpenAI will give us access to their models.\n",
        "When running the cell below, a text box should open where you can paste your API key in and hit \"enter\", granting access."
      ],
      "metadata": {
        "id": "WQAsfLXO0G1r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXyWrddj0n7u",
        "outputId": "0c79ac98-9057-4c4c-ddaf-9230a2f378a8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2. Set up PDF reading\n",
        "\n",
        "To read in a PDF with python, we need to use the PyPDF2 package. This package is built specifically to read in PDF's, so we can make use of its base functionalities and not have to write too much code ourselves.\n",
        "\n",
        "In this code cell, we define a function that uses PyPDF2 to read in the text from a PDF. It will take in a path to the PDF, and then return all of the text of the PDF into a string."
      ],
      "metadata": {
        "id": "Paj0_92i1aZe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bVjkYmgaywje"
      },
      "outputs": [],
      "source": [
        "# Function to extract text from PDF\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PyPDF2.PdfReader(pdf_path) # PDFReader class opens our PDF for us\n",
        "    text = \"\"\n",
        "    for page in reader.pages: # We loop over all of the pages in the PDF\n",
        "        text += page.extract_text() # Strings can be simply concatenated\n",
        "    return text # The returned text is a string of all of the text in the pdf."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can use that function on a PDF.\n",
        "\n",
        "This function assumes we have a path to our PDF, so we need it in our local environment.\n",
        "\n",
        "In Google Colab, in the menu to the left, their should be an \"upload\" option. You can upload any PDF file directly from your computer into the session storage to use the function on."
      ],
      "metadata": {
        "id": "ACicFqcv2Fbf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_path = 'sample.pdf' # this can be a path to any named PDF file!\n",
        "pdf_text = extract_text_from_pdf(pdf_path)"
      ],
      "metadata": {
        "id": "BOhYtRLv2Ibw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can look at what's in `pdf_text` to ensure it matches what was on our pdf."
      ],
      "metadata": {
        "id": "7lJL3aCY3pjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(pdf_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxJuH7vy3vAJ",
        "outputId": "78c04726-193a-4698-a465-4cd6f2628318"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample PDFThis is a simple PDF ﬁle. Fun fun fun.Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Phasellus facilisis odio sed mi. Curabitur suscipit. Nullam vel nisi. Etiam semper ipsum ut lectus. Proin aliquam, erat eget pharetra commodo, eros mi condimentum quam, sed commodo justo quam ut velit. Integer a erat. Cras laoreet ligula cursus enim. Aenean scelerisque velit et tellus. Vestibulum dictum aliquet sem. Nulla facilisi. Vestibulum accumsan ante vitae elit. Nulla erat dolor, blandit in, rutrum quis, semper pulvinar, enim. Nullam varius congue risus. Vivamus sollicitudin, metus ut interdum eleifend, nisi tellus pellentesque elit, tristique accumsan eros quam et risus. Suspendisse libero odio, mattis sit amet, aliquet eget, hendrerit vel, nulla. Sed vitae augue. Aliquam erat volutpat. Aliquam feugiat vulputate nisl. Suspendisse quis nulla pretium ante pretium mollis. Proin velit ligula, sagittis at, egestas a, pulvinar quis, nisl.Pellentesque sit amet lectus. Praesent pulvinar, nunc quis iaculis sagittis, justo quam lobortis tortor, sed vestibulum dui metus venenatis est. Nunc cursus ligula. Nulla facilisi. Phasellus ullamcorper consectetuer ante. Duis tincidunt, urna id condimentum luctus, nibh ante vulputate sapien, id sagittis massa orci ut enim. Pellentesque vestibulum convallis sem. Nulla consequat quam ut nisl. Nullam est. Curabitur tincidunt dapibus lorem. Proin velit turpis, scelerisque sit amet, iaculis nec, rhoncus ac, ipsum. Phasellus lorem arcu, feugiat eu, gravida eu, consequat molestie, ipsum. Nullam vel est ut ipsum volutpat feugiat. Aenean pellentesque.In mauris. Pellentesque dui nisi, iaculis eu, rhoncus in, venenatis ac, ante. Ut odio justo, scelerisque vel, facilisis non, commodo a, pede. Cras nec massa sit amet tortor volutpat varius. Donec lacinia, neque a luctus aliquet, pede massa imperdiet ante, at varius lorem pede sed sapien. Fusce erat nibh, aliquet in, eleifend eget, commodo eget, erat. Fusce consectetuer. Cras risus tortor, porttitor nec, tristique sed, convallis semper, eros. Fusce vulputate ipsum a mauris. Phasellus mollis. Curabitur sed urna. Aliquam nec sapien non nibh pulvinar convallis. Vivamus facilisis augue quis quam. Proin cursus aliquet metus. Suspendisse lacinia. Nulla at tellus ac turpis eleifend scelerisque. Maecenas a pede vitae enim commodo interdum. Donec odio. Sed sollicitudin dui vitae justo.Morbi elit nunc, facilisis a, mollis a, molestie at, lectus. Suspendisse eget mauris eu tellus molestie cursus. Duis ut magna at justo dignissim condimentum. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Vivamus varius. Ut sit amet diam suscipit mauris ornare aliquam. Sed varius. Duis arcu. Etiam tristique massa eget dui. Phasellus congue. Aenean est erat, tincidunt eget, venenatis quis, commodo at, quam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3. Make an API call to OpenAI to chat\n",
        "\n",
        "Now, we'll set up sending a prompt to OpenAI's GPT-3.5 model. We could instead use GPT-4, given our API has access.\n",
        "\n",
        "More details on the different models that can be called with the API:\n",
        "https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4\n",
        "\n",
        "Keep in mind that the more powerful the model, the more expensive! It's best to develop with gpt-3.5 whenever possible."
      ],
      "metadata": {
        "id": "FfGgURBi2I7L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic setup for an API call with OpenAI looks like this:\n",
        "```\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"<model_name>\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"<system prompt>\"},\n",
        "    {\"role\": \"user\", \"content\": \"<user prompt>\"}\n",
        "  ]\n",
        ")\n",
        "```\n",
        "Here, we specify what model we want with `model = ...`\n",
        "The `messages` define what context we're giving to the model. There are two types of these messages, `system` and `user`.\n",
        "\n",
        "* The `system` prompt sets the behavior, guidelines, and constraints for the model. It provides initial context and instructions that the model should follow throughout the conversation.\n",
        "\n",
        "* The `user` prompt is the inputs from the user. It's what the model generates responses to.\n",
        "\n",
        "When adding in our PDF text, we'll add it to our prompt, which we'll have become the \"user\" message."
      ],
      "metadata": {
        "id": "Of1p7MEV4UTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's make a prompt string that includes our PDF text that we can call on the model. The sample PDF that I used in this example was largely not English. Let's try asking the model about the language of the PDF."
      ],
      "metadata": {
        "id": "HrzogVx86WFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_string = \"Here is some text from a pdf: \" + pdf_text + \"What language is this?\""
      ],
      "metadata": {
        "id": "qFjkBgaA6cH3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll call the oi"
      ],
      "metadata": {
        "id": "9U09x-SJ7Img"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI() # this connects to OpenAI, and makes use of our API key we set earlier.\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\", # We'll use gpt-3.5 to experiment with. But this could be changed if necessary.\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, # We don't need much guidance here, this is a very simple system prompt.\n",
        "    {\"role\": \"user\", \"content\": prompt_string} # Insert our prompt string here!\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "6-Q7UZA92D59"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"completions\" object that we get out from the chat call contains a lot of information, more about that here: https://platform.openai.com/docs/api-reference/chat/create\n",
        "\n",
        "Four our purposes, let's just look at the response message."
      ],
      "metadata": {
        "id": "NDbNhSDu7VQy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NCDRbvk7Uba",
        "outputId": "ee1088d6-0d3b-428c-b619-99d632ebf211"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='The text you provided appears to be in Latin. Lorem ipsum is a commonly used placeholder text in the publishing and graphic design industries to simulate the appearance of written text.', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Awesome! It looks like we sucessfully made the call, and it was accurately able to include information from the provided PDF text in the response."
      ],
      "metadata": {
        "id": "O55tM3Ui7jxG"
      }
    }
  ]
}
